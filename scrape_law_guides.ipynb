{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k7D5F45_hqB",
        "outputId": "c7c04bd9-b498-426c-8c39-e45b71005789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topics are--->  \n",
            "\n",
            "\n",
            "Divorce\n",
            "Medical Negligence\n",
            "Landlord/Tenant\n",
            "Property\n",
            "Motor Accident\n",
            "Wills / Trusts\n",
            "Criminal\n",
            "Trademark & Copyright\n",
            "Cheque Bounce\n",
            "Consumer Court\n",
            "Corporate\n",
            "Recovery\n",
            "Civil\n",
            "Tax\n",
            "Labour & Service\n",
            "Family\n",
            "Child Custody\n",
            "Muslim Law\n",
            "Documentation\n",
            "Customs & Central Excise\n",
            "Cyber Crime\n",
            "Arbitration\n",
            "Immigration\n",
            "Armed Forces Tribunal\n",
            "Insurance\n",
            "R.T.I\n",
            "Startup\n",
            "Banking / Finance\n",
            "Supreme Court\n",
            "GST\n",
            "Domestic Violence\n",
            "Breach of Contract\n",
            "Patent\n",
            "Court Marriage\n",
            "\n",
            "\n",
            "Select any Topic: divorce\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# Define the base URL of the website to scrape\n",
        "BASE_URL = \"https://lawrato.com/indian-kanoon/law-guides\"\n",
        "\n",
        "# Make a request to the page\n",
        "response = requests.get(BASE_URL)\n",
        "\n",
        "# Extract the HTML response as a BeautifulSoup object\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find all heading elements on the page\n",
        "headings = soup.find_all(\"div\", class_=\"col-lg-12 col-xs-12 colMb venue-amenities\")\n",
        "\n",
        "# Extract the heading text\n",
        "heading_text = []\n",
        "for heading in headings:\n",
        "    heading_text.append(heading.text)\n",
        "\n",
        "# Print the heading text\n",
        "for heading in heading_text:\n",
        "    print(\"Topics are---> \", heading)\n",
        "\n",
        "topic = input(\"Select any Topic: \")\n",
        "selected_topic = topic.replace(\"-law\", \"\").replace(\"-guides\", \"\")\n",
        "\n",
        "# Generate the URL\n",
        "url = f\"https://lawrato.com/indian-kanoon/{selected_topic}\"\n",
        "topic_url = f\"{url}-law-guides\"\n",
        "\n",
        "# Find heading for the particular topic\n",
        "response = requests.get(topic_url)\n",
        "\n",
        "# Extract the HTML response as a BeautifulSoup object\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find all heading elements on the page\n",
        "td = soup.find('div', class_='col-sm-8')\n",
        "\n",
        "# Find all href links in the td element\n",
        "href_links = []\n",
        "for link in td.find_all(\"a\"):\n",
        "    if link.has_attr(\"href\"):\n",
        "        href_links.append(link[\"href\"])\n",
        "\n",
        "# Remove duplicate href links\n",
        "href_links = set(href_links)\n",
        "\n",
        "# Remove href links with page numbers from the href_links list\n",
        "href_links = [\n",
        "    link for link in href_links if not re.match(r\"https://lawrato.com/indian-kanoon/divorce-law-guides?&page=\\w+\", link)\n",
        "]\n",
        "\n",
        "# Create a JSON object to store the scraped content\n",
        "scraped_content_json = {}\n",
        "\n",
        "# Iterate over the href links\n",
        "for href_link in href_links:\n",
        "\n",
        "    # Make a request to the href link\n",
        "    response = requests.get(href_link)\n",
        "\n",
        "    # Extract the HTML response as a BeautifulSoup object\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Extract the heading and content\n",
        "    heading = soup.find(\"h1\").text\n",
        "    content = soup.find_all(\"p\")\n",
        "    content = [paragraph.text.strip() for paragraph in content]\n",
        "\n",
        "    # Create a JSON object for the scraped content\n",
        "    scraped_content_json[href_link] = {\n",
        "        \"title\": heading,\n",
        "        \"content\": content,\n",
        "    }\n",
        "\n",
        "# Write the JSON object to the JSON file\n",
        "with open(\"law_guides.json\", \"w\") as json_file:\n",
        "    json.dump(scraped_content_json, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mKHA8u0g_qLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}